### Файл `docker-compose.yml`

Запускает и связывает сервисы ELK-стека (Elasticsearch, Logstash, Kibana, Filebeat) и дополнительного приложения в Docker-контейнерах. Вот, что делает каждый блок:

***

### 1. Сервис `es-hot` (Elasticsearch Hot node)
- Запускает контейнер с Elasticsearch версии 8.15.3, с именем `es-hot`.
- Настроен как горячий (hot) узел с ролями: `master`, `data_content`, `data_hot`.
- Использует JVM с 1 ГБ памяти (`ES_JAVA_OPTS`).
- Открывает порт 9200 для HTTP-запросов на все интерфейсы (`http.host=0.0.0.0`).
- Отключена безопасность `xpack.security.enabled=false` для упрощения.
- Хранит данные в volume `data01`.
- Задает высокие лимиты по памяти и открытому числу дескрипторов (ulimits).
- Включен в Docker-сеть `elastic`.
- Зависит от сервиса `es-warm` (т.е. ждет его запуска).

***

### 2. Сервис `es-warm` (Elasticsearch Warm node)
- Запускает Elasticsearch версии 8.15.3 с именем `es-warm`.
- Узел с ролями `master`, `data_warm` (хранит менее горячие данные).
- Аналогичные настройки памяти, безопасности и сети.
- Данные хранятся в volume `data02`.
- Использует ту же сеть `elastic`.
- Этот узел и `es-hot` образуют кластер `es-docker-cluster`.

***

### 3. `kibana`
- Запускает Kibana 8.15.3, сервис для визуализации и интерфейса к Elasticsearch.
- Пробрасывает порт 5601 наружу.
- Подключается к Elasticsearch по адресам `es-hot:9200` и `es-warm:9200`.
- Выполняется после запуска Elasticsearch узлов.

***

### 4. `logstash`
- Контейнер с Logstash 8.15.3, сервис для обработки и трансформации логов.
- JVM с 512 МБ памяти.
- Порты 5044 и 5046 проброшены (обычно для приема логов от Beats и других источников).
- Монтирует локальные конфиги Logstash (`logstash.conf`, `logstash.yml`).
- Часть сети `elastic`.
- Зависит от Elasticsearch (ждет их запуска).

***

### 5. `filebeat`
- Контейнер Filebeat 8.15.3 — агент для сбора и отправки логов.
- Запущен с привилегиями (`privileged: true`) и от пользователя root.
- Выполняет команду `filebeat -e -strict.perms=false`.
- Монтирует конфигурационный файл `filebeat.yml` и директории Docker для сбора контейнерных логов.
- Подключен к сети `elastic`.
- Ждет запуска Logstash.

***

### 6. `some_application`
- Дополнительное приложение на Python 3.10 Alpine.
- Монтирует локальную директорию `./pinger/` в контейнер.
- Запускает скрипт `/opt/run.py`.

***

### 7. Volumes
- Объявлены три локальных volume (`data01`, `data02`, `data03`) для хранения данных Elasticsearch.

***

### 8. Networks
- Создана сеть `elastic` с драйвером `bridge`, для связи всех контейнеров.

***

## Запуск

1. Подготовьте директории `./configs` с конфигами.
2. На хосте выполните:
   ```
   sudo sysctl -w vm.max_map_count=262144
   ```
3. Запустите Docker stack:
   ```
   docker compose up -d
   ```
4. Kibana будет готова для анализа логов по адресу:  
   `http://localhost:5601`

***

## Итог:
Данный файл поднимает кластер Elasticsearch с двумя типами нод (hot и warm), визуализацию Kibana, сбор и обработку логов через Logstash и Filebeat, а также запускает пользовательское Python-приложение. Все сервисы связаны в одну сеть и настроены для совместной работы в ELK-стеке.

### Файл `filebeat.yml` делает следующее:

***

### 1. Сбор логов Docker-контейнеров
```yaml
filebeat.inputs:
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'
```
- Filebeat читает все логи **Docker-контейнеров** из системного каталога `/var/lib/docker/containers/*/*.log` на хостовой машине.
- Такой путь подходит для большинства Linux-дистрибутивов при дефолтной конфигурации Docker.[4][8]

***

### 2. Обработка логов (processors)
```yaml
processors:
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock"
  - decode_json_fields:
      fields: ["message"]
      target: "json"
      overwrite_keys: true
```
- `add_docker_metadata`: добавляет к каждому событию метаданные контейнера: имя, image, label, id и др. — всё автоматически из Docker-сокета.
- `decode_json_fields`: пробует распарсить поле `message` как JSON. Результирующие ключи помещаются в структуру `json` (или перезаписывают существующие имена при `overwrite_keys: true`). Это делает логи структурированными и удобными для поиска и анализа в ELK.[7][8]

***

### 3. Отправка логов в Logstash
```yaml
output.logstash:
  hosts: ["logstash:5046"]
  protocol: tcp
```
- Отправляет все обработанные логи по **TCP** на Logstash (имя хоста контейнера — `logstash`, порт 5046).
- Это стандартная схема для передачи логов через Logstash, который может дополнительно парсить и фильтровать данные.[5][4]

***

### 4. Логирование самого Filebeat
```yaml
logging.json: true
logging.metrics.enabled: false
```
- Логи Filebeat выводятся в формате JSON (удобны для автоматической обработки/мониторинга).
- Метрики Filebeat отключены.

***

## Итог:

- **Filebeat** собирает логи всех Docker-контейнеров, обогащает их метаданными, парсит JSON из сообщений.
- Все логи отправляются в Logstash для дальнейшей обработки и последующей передачи в Elasticsearch/Kibana.
- Такая конфигурация подходит для централизованного и структурированного сбора логов контейнеров в ELK-стеке.

### Файл logstash.conf

Этот код конфигурации Logstash выполняет следующие функции:

***

### input {
```ruby
beats {
  port => 5046
}
```
- Logstash слушает на порту **5046** входящие события от Beats (например, Filebeat).
- Плагин **Beats input** принимает поток данных, который отправляют агенты Beats по этому порту.

***

### filter {
```ruby
json {
  source => "json"
}
```
- Фильтр пытается распарсить содержимое поля `json` в событии как JSON-объект.
- Если в поле `json` приходит строка в формате JSON, она преобразуется в отдельные поля документа.
- Помогает работать со структурированными данными, переданными агентом.

***

### output {
```ruby
elasticsearch {
  hosts => ["es-hot:9200"]
  index => "logstash-%{+YYYY.MM.dd}"
}
```
- Обработанные логи пересылаются в Elasticsearch, который слушает на хосте `es-hot` по порту 9200.
- Для индексации создается индекс с названием по шаблону `logstash-ГГГГ.ММ.ДД`, то есть новые индексы создаются по дате.

***

### Итого:

- Logstash принимает данные из Filebeat по плагину Beats на TCP-порту 5046.
- Парсит поля JSON из входящих событий для дальнейшей работы.
- Отправляет очищенные логи в Elasticsearch в ежедневные индексы.

Это стандартный pipeline для централизованного сбора, парсинга и индексирования логов из Beats в ELK-стек.
